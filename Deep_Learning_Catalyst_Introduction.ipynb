{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mrinal18/Deep_Learning_Catalyst/blob/main/Deep_Learning_Catalyst_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S98kzS2-uE-W"
      },
      "source": [
        "What is PyTorch?\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "Tensorial library that uses the power of GPUs\n",
        "A deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewuncPGoHWLj"
      },
      "source": [
        "What is PyTorch?\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "Tensorial library that uses the power of GPUs\n",
        "A deep learning research platform that provides maximum flexibility and speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idQoZG6oHS9y"
      },
      "outputs": [],
      "source": [
        "import torch  # <Ctrl> / <Shift> + <Return>\n",
        "Getting help in Jupyter\n",
        "torch.sq  # <Tab>\n",
        "\n",
        "# What about all `*Tensor`s?\n",
        "# Press <esc> to get out of help\n",
        "torch.*Tensor?\n",
        "torch.nn.Module()  # <Shift>+<Tab>\n",
        "\n",
        "# Annotate your functions / classes!\n",
        "torch.nn.Module?\n",
        "\n",
        "torch.nn.Module??\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRdne2-wHghe"
      },
      "source": [
        "Python native data types\n",
        "Python has many native datatypes. Here are the important ones:\n",
        "\n",
        "**Booleans** are either True or False.\n",
        "\n",
        "**Numbers** can be integers (1 and 2), floats (1.1 and 1.2), fractions (1/2 and 2/3), or even complex numbers.\n",
        "\n",
        "**Strings** are sequences of Unicode characters, e.g. an html document.\n",
        "\n",
        "\n",
        "**Lists** are ordered sequences of values.\n",
        "\n",
        "\n",
        "**Tuples** are ordered, immutable sequences of values.\n",
        "\n",
        "\n",
        "**Sets** are unordered bags of values.\n",
        "\n",
        "\n",
        "**Dictionaries** are unordered bags of key-value pairs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YgE4dlpH-IB"
      },
      "outputs": [],
      "source": [
        "# Generate a tensor of size 2x3x4\n",
        "t = torch.Tensor(2, 3, 4)\n",
        "type(t)\n",
        "\n",
        "# Get the size of the tensor\n",
        "t.size()\n",
        "\n",
        "# t.size() is a classic tuple =>\n",
        "print('t size:', ' \\u00D7 '.join(map(str, t.size())))\n",
        "\n",
        "# prints dimensional space and sub-dimensions\n",
        "print(f'point in a {t.numel()} dimensional space')\n",
        "print(f'organised in {t.dim()} sub-dimensions')\n",
        "\n",
        "\n",
        "# Mind the underscore!\n",
        "# Any operation that mutates a tensor in-place is post-fixed with an _.\n",
        "# For example: x.copy_(y), x.t_(), x.random_(n) will change x.\n",
        "t.random_(10)\n",
        "\n",
        "# Creates a 1D tensor of integers 1 to 4\n",
        "v = torch.Tensor([1, 2, 3, 4])\n",
        "v\n",
        "# Print number of dimensions (1D) and size of tensor\n",
        "print(f'dim: {v.dim()}, size: {v.size()[0]}')\n",
        "w = torch.Tensor([1, 0, 2, 0])\n",
        "w\n",
        "# Element-wise multiplication\n",
        "v * w\n",
        "# Scalar product: 1*1 + 2*0 + 3*2 + 4*0\n",
        "v @ w\n",
        "# In-place replacement of random number from 0 to 10\n",
        "x = torch.Tensor(5).random_(10)\n",
        "x\n",
        "print(f'first: {x[0]}, last: {x[-1]}')\n",
        "# Extract sub-Tensor [from:to)\n",
        "x[1:2 + 1]\n",
        "v\n",
        "# Create a tensor with integers ranging from 1 to 5, excluding 5\n",
        "v = torch.arange(1, 4 + 1)\n",
        "v\n",
        "# Square all elements in the tensor\n",
        "print(v.pow(2), v)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhFDO03XvIg4"
      },
      "source": [
        "### **Introduction To Catalyst** \n",
        "\n",
        "Catalyst is a PyTorch framework for Deep Learning Research and Development. It focuses on reproducibility, rapid experimentation, and codebase reuse so you can create something new rather than write yet another train loop.\n",
        "Break the cycle – use the Catalyst!\n",
        "\n",
        "![Catalyst Image](figures/Catalyst.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv4LjERuvy6M"
      },
      "source": [
        "for referencem , please refer to https://github.com/catalyst-team/catalyst\n",
        "\n",
        "### **Getting Started**\n",
        "\n",
        "```\n",
        "pip install -U catalyst\n",
        "```\n",
        "\n",
        "###How to start your journey with Catalyst\n",
        "\n",
        "1. Start with Catalyst 101 — Accelerated PyTorch introduction.\n",
        "Check minimal examples.\n",
        "2. Try notebook tutorials with Google Colab.\n",
        "3. Read blogposts with use-cases and guides (and Config API intro).\n",
        "4. Go through advanced classification, detection and segmentation pipelines with Config API. More pipelines available under projects section.\n",
        "\n",
        "\n",
        "source: https://opensourcelibs.com/lib/catalyst"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nj7F_Sw4w0PI"
      },
      "source": [
        "### Examples using Catalyst\n",
        "\n",
        "##Linear Regression Using Catalyst\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF5ojlmwtwZ8"
      },
      "source": [
        "Introduction to Linear Regression: \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAhc2snFuhIq"
      },
      "outputs": [],
      "source": [
        "## import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from catalyst.dl import SupervisedRunner\n",
        "\n",
        "# data\n",
        "num_samples, num_features = int(1e4), int(1e1)\n",
        "X, y = torch.rand(num_samples, num_features), torch.rand(num_samples)\n",
        "dataset = TensorDataset(X, y)\n",
        "loader = DataLoader(dataset, batch_size=32, num_workers=1)\n",
        "loaders = {\"train\": loader, \"valid\": loader}\n",
        "\n",
        "# model, criterion, optimizer, scheduler\n",
        "model = torch.nn.Linear(num_features, 1)\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, [3, 6])\n",
        "\n",
        "# model training\n",
        "runner = SupervisedRunner()\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    loaders=loaders,\n",
        "    logdir=\"./logdir\",\n",
        "    num_epochs=8,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c32kcSBUwyzY"
      },
      "source": [
        "## MNIST classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eefRLqOixCgH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from catalyst import dl, utils\n",
        "from catalyst.data import ToTensor\n",
        "from catalyst.contrib.datasets import MNIST\n",
        "\n",
        "model = nn.Sequential(nn.Flatten(), nn.Linear(28 * 28, 10))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.02)\n",
        "\n",
        "train_data = MNIST(os.getcwd(), train=True, download=True, transform=ToTensor())\n",
        "valid_data = MNIST(os.getcwd(), train=False, download=True, transform=ToTensor())\n",
        "loaders = {\n",
        "    \"train\": DataLoader(train_data, batch_size=32),\n",
        "    \"valid\": DataLoader(valid_data, batch_size=32),\n",
        "}\n",
        "\n",
        "runner = dl.SupervisedRunner(\n",
        "    input_key=\"features\", output_key=\"logits\", target_key=\"targets\", loss_key=\"loss\"\n",
        ")\n",
        "\n",
        "# model training\n",
        "runner.train(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    loaders=loaders,\n",
        "    num_epochs=1,\n",
        "    callbacks=[\n",
        "        dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk_args=(1, 3, 5)),\n",
        "        dl.PrecisionRecallF1SupportCallback(\n",
        "            input_key=\"logits\", target_key=\"targets\", num_classes=10\n",
        "        ),\n",
        "    ],\n",
        "    logdir=\"./logs\",\n",
        "    valid_loader=\"valid\",\n",
        "    valid_metric=\"loss\",\n",
        "    minimize_valid_metric=True,\n",
        "    verbose=True,\n",
        "    load_best_on_end=True,\n",
        ")\n",
        "\n",
        "# model evaluation\n",
        "metrics = runner.evaluate_loader(\n",
        "    loader=loaders[\"valid\"],\n",
        "    callbacks=[dl.AccuracyCallback(input_key=\"logits\", target_key=\"targets\", topk_args=(1, 3, 5))],\n",
        ")\n",
        "assert \"accuracy\" in metrics.keys()\n",
        "\n",
        "# model inference\n",
        "for prediction in runner.predict_loader(loader=loaders[\"valid\"]):\n",
        "    assert prediction[\"logits\"].detach().cpu().numpy().shape[-1] == 10\n",
        "\n",
        "features_batch = next(iter(loaders[\"valid\"]))[0]\n",
        "# model stochastic weight averaging\n",
        "model.load_state_dict(utils.get_averaged_weights_by_path_mask(logdir=\"./logs\", path_mask=\"*.pth\"))\n",
        "# model tracing\n",
        "utils.trace_model(model=runner.model, batch=features_batch)\n",
        "# model quantization\n",
        "utils.quantize_model(model=runner.model)\n",
        "# model pruning\n",
        "utils.prune_model(model=runner.model, pruning_fn=\"l1_unstructured\", amount=0.8)\n",
        "# onnx export\n",
        "utils.onnx_export(model=runner.model, batch=features_batch, file=\"./logs/mnist.onnx\", verbose=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyO73vzn8VHUjK8xyNMIpWX4",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Deep_Learning_Catalyst_Introduction",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
