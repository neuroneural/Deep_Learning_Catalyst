{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:51.161763Z","iopub.status.busy":"2022-01-22T15:55:51.161511Z","iopub.status.idle":"2022-01-22T15:55:51.165623Z","shell.execute_reply":"2022-01-22T15:55:51.164626Z","shell.execute_reply.started":"2022-01-22T15:55:51.161734Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","import torchtext\n","import time\n","import random\n","import pandas as pd\n","import spacy\n"]},{"cell_type":"markdown","metadata":{},"source":["# Import Required Libraries & Data Loading"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:51.178773Z","iopub.status.busy":"2022-01-22T15:55:51.178323Z","iopub.status.idle":"2022-01-22T15:55:52.913605Z","shell.execute_reply":"2022-01-22T15:55:52.912893Z","shell.execute_reply.started":"2022-01-22T15:55:51.178736Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(50000, 2)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Probably my all-time favorite movie, a story o...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>I sure would like to see a resurrection of a u...</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>This show was an amazing, fresh &amp; innovative i...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Encouraged by the positive comments about this...</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>If you like original gut wrenching laughter yo...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review sentiment\n","0  One of the other reviewers has mentioned that ...  positive\n","1  A wonderful little production. <br /><br />The...  positive\n","2  I thought this was a wonderful way to spend ti...  positive\n","3  Basically there's a family where a little boy ...  negative\n","4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n","5  Probably my all-time favorite movie, a story o...  positive\n","6  I sure would like to see a resurrection of a u...  positive\n","7  This show was an amazing, fresh & innovative i...  negative\n","8  Encouraged by the positive comments about this...  negative\n","9  If you like original gut wrenching laughter yo...  positive"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#importing the training data\n","df=pd.read_csv('IMDB Dataset.csv')\n","print(df.shape)\n","df.head(10)"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:52.915240Z","iopub.status.busy":"2022-01-22T15:55:52.914817Z","iopub.status.idle":"2022-01-22T15:55:52.931074Z","shell.execute_reply":"2022-01-22T15:55:52.930198Z","shell.execute_reply.started":"2022-01-22T15:55:52.915202Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","sentiment : 0 = negative, 1 = positive \n","use the following to get the sentiment of a sentence :  \n","sentiment = 0 if sentiment is negative else 1\n","\n","\n","use np.where to get the sentiment of a sentence :\n","\"\"\"\n","df['sentiment'] = np.where(df['sentiment'] == 'positive', 1, 0)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:52.933556Z","iopub.status.busy":"2022-01-22T15:55:52.933295Z","iopub.status.idle":"2022-01-22T15:55:52.942961Z","shell.execute_reply":"2022-01-22T15:55:52.942162Z","shell.execute_reply.started":"2022-01-22T15:55:52.933524Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>review</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              review  sentiment\n","0  One of the other reviewers has mentioned that ...          1\n","1  A wonderful little production. <br /><br />The...          1\n","2  I thought this was a wonderful way to spend ti...          1\n","3  Basically there's a family where a little boy ...          0\n","4  Petter Mattei's \"Love in the Time of Money\" is...          1"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:52.944777Z","iopub.status.busy":"2022-01-22T15:55:52.944484Z","iopub.status.idle":"2022-01-22T15:55:52.951178Z","shell.execute_reply":"2022-01-22T15:55:52.950461Z","shell.execute_reply.started":"2022-01-22T15:55:52.944743Z"},"trusted":true},"outputs":[],"source":["df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:52.953080Z","iopub.status.busy":"2022-01-22T15:55:52.952741Z","iopub.status.idle":"2022-01-22T15:55:53.553818Z","shell.execute_reply":"2022-01-22T15:55:53.553120Z","shell.execute_reply.started":"2022-01-22T15:55:52.952969Z"},"trusted":true},"outputs":[],"source":["\"\"\"\n","Load the spacy model and load the English language model from https://spacy.io/usage/models\n","\"\"\"\n","spacy.### ADD YOUR SPACY MODEL HERE ###"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:53.629426Z","iopub.status.busy":"2022-01-22T15:55:53.629143Z","iopub.status.idle":"2022-01-22T15:55:53.637675Z","shell.execute_reply":"2022-01-22T15:55:53.636930Z","shell.execute_reply.started":"2022-01-22T15:55:53.629373Z"},"trusted":true},"outputs":[],"source":["# general Settings\n","\n","RANDOM_SEED = 123\n","torch.manual_seed(RANDOM_SEED)\n","\n","VOCABULARY_SIZE = 20000\n","LEARNING_RATE = ### ADD YOUR LEARNING RATE HERE ###\n","BATCH_SIZE = ### ADD YOUR BATCH SIZE HERE ###\n","NUM_EPOCHS = ### ADD YOUR NUMBER OF EPOCHS HERE ###\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","EMBEDDING_DIM = ### ADD YOUR EMBEDDING DIMENSION HERE ###\n","HIDDEN_DIM = ### ADD YOUR HIDDEN DIMENSION HERE ###\n","NUM_CLASSES = 2"]},{"cell_type":"markdown","metadata":{},"source":["# Text & label Preparation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:53.639530Z","iopub.status.busy":"2022-01-22T15:55:53.639045Z","iopub.status.idle":"2022-01-22T15:55:54.191068Z","shell.execute_reply":"2022-01-22T15:55:54.190361Z","shell.execute_reply.started":"2022-01-22T15:55:53.639494Z"},"trusted":true},"outputs":[],"source":["# Define feature processing\n","\"\"\"\n","Define the fields for the data.\n","\"\"\"\n","TEXT = torchtext.legacy.data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:54.194504Z","iopub.status.busy":"2022-01-22T15:55:54.194231Z","iopub.status.idle":"2022-01-22T15:55:54.198370Z","shell.execute_reply":"2022-01-22T15:55:54.197471Z","shell.execute_reply.started":"2022-01-22T15:55:54.194470Z"},"trusted":true},"outputs":[],"source":["# Define Label processing\n","LABEL = torchtext.legacy.data.LabelField(dtype = torch.long)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:54.200276Z","iopub.status.busy":"2022-01-22T15:55:54.199959Z","iopub.status.idle":"2022-01-22T15:55:57.099915Z","shell.execute_reply":"2022-01-22T15:55:57.099168Z","shell.execute_reply.started":"2022-01-22T15:55:54.200243Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TEXT_COLUMN_NAME</th>\n","      <th>LABEL_COLUMN_NAME</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>One of the other reviewers has mentioned that ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>I thought this was a wonderful way to spend ti...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Basically there's a family where a little boy ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                    TEXT_COLUMN_NAME  LABEL_COLUMN_NAME\n","0  One of the other reviewers has mentioned that ...                  1\n","1  A wonderful little production. <br /><br />The...                  1\n","2  I thought this was a wonderful way to spend ti...                  1\n","3  Basically there's a family where a little boy ...                  0\n","4  Petter Mattei's \"Love in the Time of Money\" is...                  1"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","Define the fields for the data.\n","\"\"\"\n","\n","df.to_csv('moviedata.csv', index = None)\n","df = pd.read_csv('moviedata.csv')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:55:57.102513Z","iopub.status.busy":"2022-01-22T15:55:57.102056Z","iopub.status.idle":"2022-01-22T15:56:41.889075Z","shell.execute_reply":"2022-01-22T15:56:41.888358Z","shell.execute_reply.started":"2022-01-22T15:55:57.102470Z"},"trusted":true},"outputs":[],"source":["# process the dataset\n","\n","fields = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\n","\n","dataset = torchtext.legacy.data.TabularDataset(\n","                    path = , ### ADD YOUR DATASET PATH HERE ###\n","                    format = , ### ADD YOUR DATASET FORMAT HERE ###\n","                    skip_header = , ### ADD YOUR SKIP HEADER HERE ### \n","                    fields =  ### ADD YOUR FIELDS HERE ### \n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Data Split"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:41.890714Z","iopub.status.busy":"2022-01-22T15:56:41.890459Z","iopub.status.idle":"2022-01-22T15:56:41.961168Z","shell.execute_reply":"2022-01-22T15:56:41.960371Z","shell.execute_reply.started":"2022-01-22T15:56:41.890680Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of train data 40000\n","Length of test data 10000\n"]}],"source":["# Split dataset into train and test set\n","\n","train_data, test_data = dataset.split(split_ratio = [0.8, 0.2], random_state = random.seed(RANDOM_SEED))\n","\n","print('Length of train data', len(train_data))\n","print('Length of test data', len(test_data))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:41.962867Z","iopub.status.busy":"2022-01-22T15:56:41.962611Z","iopub.status.idle":"2022-01-22T15:56:42.018970Z","shell.execute_reply":"2022-01-22T15:56:42.017378Z","shell.execute_reply.started":"2022-01-22T15:56:41.962832Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of train data 34000\n","Length of valid data 6000\n"]}],"source":["train_data, val_data = train_data.split(split_ratio = [0.85, 0.15], random_state = random.seed(RANDOM_SEED))\n","\n","print('Length of train data', len(train_data))\n","print('Length of valid data', len(val_data))"]},{"cell_type":"markdown","metadata":{},"source":["# Data Observation after Tokenization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:42.020384Z","iopub.status.busy":"2022-01-22T15:56:42.020132Z","iopub.status.idle":"2022-01-22T15:56:42.026208Z","shell.execute_reply":"2022-01-22T15:56:42.025377Z","shell.execute_reply.started":"2022-01-22T15:56:42.020349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'TEXT_COLUMN_NAME': ['Flipping', 'through', 'the', 'channels', 'I', 'was', 'lucky', 'enough', 'to', 'stumble', 'upon', 'the', 'beginning', 'of', 'this', 'movie', '.', 'I', 'must', 'admit', 'that', 'it', 'grabbed', 'my', 'attention', 'almost', 'immediately', '.', 'I', 'love', 'older', 'films', 'and', 'this', 'is', 'or', 'should', 'be', 'considered', 'a', 'classic', '!', 'One', 'of', 'the', 'most', 'wonderful', 'rarities', 'of', 'this', 'movie', 'is', 'that', 'the', 'main', 'character', 'was', 'not', 'only', 'female', 'but', 'she', 'was', 'also', 'a', 'bad', 'girl', '.', 'I', 'highly', 'recommend', 'this', 'movie', '!'], 'LABEL_COLUMN_NAME': '1'}\n"]}],"source":["# Look at first traning example\n","\n","print(vars(train_data.examples[2000]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:42.028212Z","iopub.status.busy":"2022-01-22T15:56:42.027904Z","iopub.status.idle":"2022-01-22T15:56:43.688300Z","shell.execute_reply":"2022-01-22T15:56:43.687534Z","shell.execute_reply.started":"2022-01-22T15:56:42.028178Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulary size: 20002\n","Label Size: 2\n"]}],"source":["# Build Vocabulary\n","\n","TEXT.build_vocab(train_data, max_size = VOCABULARY_SIZE)\n","LABEL.build_vocab(train_data)\n","\n","print(f'vocabulary size: {len(TEXT.vocab)}')\n","print(f'Label Size: {len(LABEL.vocab)}')"]},{"cell_type":"markdown","metadata":{},"source":[" 2 extra value in vocabulary is because added (unknown) and (padding)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:43.690179Z","iopub.status.busy":"2022-01-22T15:56:43.689727Z","iopub.status.idle":"2022-01-22T15:56:43.726493Z","shell.execute_reply":"2022-01-22T15:56:43.725793Z","shell.execute_reply.started":"2022-01-22T15:56:43.690127Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[('the', 390972), (',', 369444), ('.', 318509), ('a', 210502), ('and', 210008), ('of', 194659), ('to', 180163), ('is', 145895), ('in', 118266), ('I', 105681), ('it', 103588), ('that', 93995), ('\"', 85535), (\"'s\", 83149), ('this', 81775), ('-', 71249), ('/><br', 68787), ('was', 67372), ('as', 57734), ('movie', 57572), ('with', 57543), ('for', 56557), ('film', 52382), ('The', 51251), ('but', 46575), ('(', 44813), ('on', 44528), (\"n't\", 44474), (')', 44145), ('you', 42196)]\n"]}],"source":["# Print the most common words: Use the most_common method of the TEXT vocabulary\n","most_common_words = \n","print(most_common_words)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:43.727759Z","iopub.status.busy":"2022-01-22T15:56:43.727533Z","iopub.status.idle":"2022-01-22T15:56:43.733148Z","shell.execute_reply":"2022-01-22T15:56:43.732231Z","shell.execute_reply.started":"2022-01-22T15:56:43.727727Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['<unk>', '<pad>', 'the', ',', '.', 'a', 'and', 'of', 'to', 'is', 'in', 'I', 'it', 'that', '\"', \"'s\", 'this', '-', '/><br', 'was']\n"]}],"source":["# Token corresponding to first 10 Indices\n","\n","print(TEXT.vocab.itos[:20]) #itos = Integer to string"]},{"cell_type":"markdown","metadata":{},"source":["# Data Preparation for Batch wise Implimentation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:43.760843Z","iopub.status.busy":"2022-01-22T15:56:43.760082Z","iopub.status.idle":"2022-01-22T15:56:43.766731Z","shell.execute_reply":"2022-01-22T15:56:43.766017Z","shell.execute_reply.started":"2022-01-22T15:56:43.760804Z"},"trusted":true},"outputs":[],"source":["# Define Dataloader\n","\n","train_loader, valid_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n","        , ### ADD YOUR SPLIT DATA HERE (Make sure you add it in a tuple) ###\n","        batch_size = , ### ADD YOUR BATCH SIZE HERE ###\n","        sort_within_batch = , ### ADD YOUR SORT WITHIN BATCH HERE ### \n","        sort_key = lambda x : len(x.TEXT_COLUMN_NAME), \n","        #device = DEVICE\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:43.768827Z","iopub.status.busy":"2022-01-22T15:56:43.768197Z","iopub.status.idle":"2022-01-22T15:56:43.900963Z","shell.execute_reply":"2022-01-22T15:56:43.900283Z","shell.execute_reply.started":"2022-01-22T15:56:43.768790Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Train\n","Text matrix size: torch.Size([1154, 128])\n","Target vector size: torch.Size([128])\n","\n","Valid:\n","Text matrix size: torch.Size([56, 128])\n","Target vector size: torch.Size([128])\n","\n","Test:\n","Text matrix size: torch.Size([50, 128])\n","Target vector size: torch.Size([128])\n"]}],"source":["# Testing the iterators (note that the number of rows depends on the longest document in the respective batch):\n","\n","print('Train')\n","for batch in train_loader:\n","    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n","    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n","    break\n","    \n","print('\\nValid:')\n","for batch in valid_loader:\n","    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n","    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n","    break\n","    \n","print('\\nTest:')\n","for batch in test_loader:\n","    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n","    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:43.902778Z","iopub.status.busy":"2022-01-22T15:56:43.902325Z","iopub.status.idle":"2022-01-22T15:56:43.909421Z","shell.execute_reply":"2022-01-22T15:56:43.908776Z","shell.execute_reply.started":"2022-01-22T15:56:43.902740Z"},"trusted":true},"outputs":[],"source":["train_loader, valid_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n","        , ### ADD YOUR SPLIT DATA HERE (Make sure you add it in a tuple) ###\n","        batch_size = , ### ADD YOUR BATCH SIZE HERE ###\n","        sort_within_batch = , ### ADD YOUR SORT WITHIN BATCH HERE ###\n","        sort_key = lambda x : len(x.TEXT_COLUMN_NAME),\n","        device = DEVICE\n","    )"]},{"cell_type":"markdown","metadata":{},"source":["# Model Building"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:43.910544Z","iopub.status.busy":"2022-01-22T15:56:43.910274Z","iopub.status.idle":"2022-01-22T15:56:43.920687Z","shell.execute_reply":"2022-01-22T15:56:43.919977Z","shell.execute_reply.started":"2022-01-22T15:56:43.910510Z"},"trusted":true},"outputs":[],"source":["class RNN(torch.nn.Module):\n","    \n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n","        super().__init__()\n","        ### ADD YOUR CODE HERE ###\n","        \n","        \n","        ### END YOUR CODE ### \n","\n","    def forward(self, text):\n","        ### ADD YOUR CODE HERE ###\n","        # text dim: [sentence length, batch size]\n","        \n","        # embedded dim: [sentence length, batch size, embedding dim]\n","        \n","        # output dim: [sentence length, batch size, hidden dim]\n","        # hidden dim: [1, batch size, hidden dim]\n","\n","        # hidden dim: [batch size, hidden dim]\n","\n","        \n","        ### END YOUR CODE ###\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:43.922337Z","iopub.status.busy":"2022-01-22T15:56:43.921742Z","iopub.status.idle":"2022-01-22T15:56:51.579010Z","shell.execute_reply":"2022-01-22T15:56:51.578073Z","shell.execute_reply.started":"2022-01-22T15:56:43.922287Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(RANDOM_SEED)\n","model = RNN(input_dim=, ### ADD YOUR INPUT DIM HERE. This can be the length of your vocabulary or the embedding dim ###\n","            embedding_dim=, ### ADD YOUR EMBEDDING DIM HERE ###\n","            hidden_dim=, ### ADD YOUR HIDDEN DIM HERE ###\n","            output_dim=  ### ADD NUMBER OF CLASSES HERE ###\n",")\n","\n","model = model.to(DEVICE)\n","optimizer = ### ADD YOUR OPTIMIZER HERE ###"]},{"cell_type":"markdown","metadata":{},"source":["# Define Accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:51.581205Z","iopub.status.busy":"2022-01-22T15:56:51.580712Z","iopub.status.idle":"2022-01-22T15:56:51.589897Z","shell.execute_reply":"2022-01-22T15:56:51.588931Z","shell.execute_reply.started":"2022-01-22T15:56:51.581131Z"},"trusted":true},"outputs":[],"source":["def compute_accuracy(model, data_loader, device):\n","\n","    with torch.no_grad():\n","\n","        correct_pred, num_examples = 0, 0\n","\n","        for i, (features, targets) in enumerate(data_loader):\n","\n","            features = features.to(device)\n","            targets = targets.float().to(device)\n","\n","            logits = model(features)\n","            _, predicted_labels = torch.max(logits, 1)\n","\n","            num_examples += targets.size(0)\n","            correct_pred += (predicted_labels == targets).sum()\n","    return correct_pred.float()/num_examples * 100"]},{"cell_type":"markdown","metadata":{},"source":["# Model Run"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T15:56:51.596066Z","iopub.status.busy":"2022-01-22T15:56:51.595269Z","iopub.status.idle":"2022-01-22T16:41:22.979843Z","shell.execute_reply":"2022-01-22T16:41:22.979001Z","shell.execute_reply.started":"2022-01-22T15:56:51.596024Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 001/050 | Batch 000/266 | Loss: 0.7136\n","Epoch: 001/050 | Batch 050/266 | Loss: 0.6993\n","Epoch: 001/050 | Batch 100/266 | Loss: 0.6898\n","Epoch: 001/050 | Batch 150/266 | Loss: 0.6925\n","Epoch: 001/050 | Batch 200/266 | Loss: 0.6960\n","Epoch: 001/050 | Batch 250/266 | Loss: 0.6951\n","training accuracy: 49.94%\n","valid accuracy: 49.83%\n","Time elapsed: 0.91 min\n","Epoch: 002/050 | Batch 000/266 | Loss: 0.6984\n","Epoch: 002/050 | Batch 050/266 | Loss: 0.6915\n","Epoch: 002/050 | Batch 100/266 | Loss: 0.6940\n","Epoch: 002/050 | Batch 150/266 | Loss: 0.6953\n","Epoch: 002/050 | Batch 200/266 | Loss: 0.6935\n","Epoch: 002/050 | Batch 250/266 | Loss: 0.6922\n","training accuracy: 50.00%\n","valid accuracy: 50.07%\n","Time elapsed: 1.80 min\n","Epoch: 003/050 | Batch 000/266 | Loss: 0.6908\n","Epoch: 003/050 | Batch 050/266 | Loss: 0.6975\n","Epoch: 003/050 | Batch 100/266 | Loss: 0.7004\n","Epoch: 003/050 | Batch 150/266 | Loss: 0.6952\n","Epoch: 003/050 | Batch 200/266 | Loss: 0.6906\n","Epoch: 003/050 | Batch 250/266 | Loss: 0.6913\n","training accuracy: 50.34%\n","valid accuracy: 50.15%\n","Time elapsed: 2.68 min\n","Epoch: 004/050 | Batch 000/266 | Loss: 0.6922\n","Epoch: 004/050 | Batch 050/266 | Loss: 0.6990\n","Epoch: 004/050 | Batch 100/266 | Loss: 0.6922\n","Epoch: 004/050 | Batch 150/266 | Loss: 0.6963\n","Epoch: 004/050 | Batch 200/266 | Loss: 0.6948\n","Epoch: 004/050 | Batch 250/266 | Loss: 0.6914\n","training accuracy: 50.35%\n","valid accuracy: 50.00%\n","Time elapsed: 3.57 min\n","Epoch: 005/050 | Batch 000/266 | Loss: 0.6903\n","Epoch: 005/050 | Batch 050/266 | Loss: 0.6928\n","Epoch: 005/050 | Batch 100/266 | Loss: 0.6912\n","Epoch: 005/050 | Batch 150/266 | Loss: 0.6949\n","Epoch: 005/050 | Batch 200/266 | Loss: 0.7001\n","Epoch: 005/050 | Batch 250/266 | Loss: 0.6893\n","training accuracy: 50.37%\n","valid accuracy: 50.30%\n","Time elapsed: 4.47 min\n","Epoch: 006/050 | Batch 000/266 | Loss: 0.6971\n","Epoch: 006/050 | Batch 050/266 | Loss: 0.6890\n","Epoch: 006/050 | Batch 100/266 | Loss: 0.6867\n","Epoch: 006/050 | Batch 150/266 | Loss: 0.7023\n","Epoch: 006/050 | Batch 200/266 | Loss: 0.6900\n","Epoch: 006/050 | Batch 250/266 | Loss: 0.6885\n","training accuracy: 50.19%\n","valid accuracy: 50.47%\n","Time elapsed: 5.35 min\n","Epoch: 007/050 | Batch 000/266 | Loss: 0.6885\n","Epoch: 007/050 | Batch 050/266 | Loss: 0.7028\n","Epoch: 007/050 | Batch 100/266 | Loss: 0.6885\n","Epoch: 007/050 | Batch 150/266 | Loss: 0.6889\n","Epoch: 007/050 | Batch 200/266 | Loss: 0.6877\n","Epoch: 007/050 | Batch 250/266 | Loss: 0.6882\n","training accuracy: 50.41%\n","valid accuracy: 50.20%\n","Time elapsed: 6.24 min\n","Epoch: 008/050 | Batch 000/266 | Loss: 0.6899\n","Epoch: 008/050 | Batch 050/266 | Loss: 0.7012\n","Epoch: 008/050 | Batch 100/266 | Loss: 0.6880\n","Epoch: 008/050 | Batch 150/266 | Loss: 0.6928\n","Epoch: 008/050 | Batch 200/266 | Loss: 0.6917\n","Epoch: 008/050 | Batch 250/266 | Loss: 0.6895\n","training accuracy: 61.00%\n","valid accuracy: 60.33%\n","Time elapsed: 7.13 min\n","Epoch: 009/050 | Batch 000/266 | Loss: 0.6768\n","Epoch: 009/050 | Batch 050/266 | Loss: 0.6781\n","Epoch: 009/050 | Batch 100/266 | Loss: 0.6610\n","Epoch: 009/050 | Batch 150/266 | Loss: 0.6498\n","Epoch: 009/050 | Batch 200/266 | Loss: 0.6359\n","Epoch: 009/050 | Batch 250/266 | Loss: 0.5808\n","training accuracy: 72.84%\n","valid accuracy: 67.05%\n","Time elapsed: 8.03 min\n","Epoch: 010/050 | Batch 000/266 | Loss: 0.5725\n","Epoch: 010/050 | Batch 050/266 | Loss: 0.5274\n","Epoch: 010/050 | Batch 100/266 | Loss: 0.4851\n","Epoch: 010/050 | Batch 150/266 | Loss: 0.4642\n","Epoch: 010/050 | Batch 200/266 | Loss: 0.5052\n","Epoch: 010/050 | Batch 250/266 | Loss: 0.5080\n","training accuracy: 80.24%\n","valid accuracy: 75.40%\n","Time elapsed: 8.92 min\n","Epoch: 011/050 | Batch 000/266 | Loss: 0.4163\n","Epoch: 011/050 | Batch 050/266 | Loss: 0.3634\n","Epoch: 011/050 | Batch 100/266 | Loss: 0.4942\n","Epoch: 011/050 | Batch 150/266 | Loss: 0.3994\n","Epoch: 011/050 | Batch 200/266 | Loss: 0.3422\n","Epoch: 011/050 | Batch 250/266 | Loss: 0.3313\n","training accuracy: 83.18%\n","valid accuracy: 76.53%\n","Time elapsed: 9.81 min\n","Epoch: 012/050 | Batch 000/266 | Loss: 0.3633\n","Epoch: 012/050 | Batch 050/266 | Loss: 0.3800\n","Epoch: 012/050 | Batch 100/266 | Loss: 0.4197\n","Epoch: 012/050 | Batch 150/266 | Loss: 0.3929\n","Epoch: 012/050 | Batch 200/266 | Loss: 0.3593\n","Epoch: 012/050 | Batch 250/266 | Loss: 0.5156\n","training accuracy: 69.09%\n","valid accuracy: 70.75%\n","Time elapsed: 10.70 min\n","Epoch: 013/050 | Batch 000/266 | Loss: 0.5412\n","Epoch: 013/050 | Batch 050/266 | Loss: 0.3211\n","Epoch: 013/050 | Batch 100/266 | Loss: 0.4427\n","Epoch: 013/050 | Batch 150/266 | Loss: 0.4895\n","Epoch: 013/050 | Batch 200/266 | Loss: 0.4497\n","Epoch: 013/050 | Batch 250/266 | Loss: 0.4857\n","training accuracy: 79.30%\n","valid accuracy: 74.05%\n","Time elapsed: 11.59 min\n","Epoch: 014/050 | Batch 000/266 | Loss: 0.4381\n","Epoch: 014/050 | Batch 050/266 | Loss: 0.4736\n","Epoch: 014/050 | Batch 100/266 | Loss: 0.4543\n","Epoch: 014/050 | Batch 150/266 | Loss: 0.5307\n","Epoch: 014/050 | Batch 200/266 | Loss: 0.4419\n","Epoch: 014/050 | Batch 250/266 | Loss: 0.4583\n","training accuracy: 83.13%\n","valid accuracy: 76.15%\n","Time elapsed: 12.48 min\n","Epoch: 015/050 | Batch 000/266 | Loss: 0.3551\n","Epoch: 015/050 | Batch 050/266 | Loss: 0.3994\n","Epoch: 015/050 | Batch 100/266 | Loss: 0.3667\n","Epoch: 015/050 | Batch 150/266 | Loss: 0.3518\n","Epoch: 015/050 | Batch 200/266 | Loss: 0.5011\n","Epoch: 015/050 | Batch 250/266 | Loss: 0.4299\n","training accuracy: 83.60%\n","valid accuracy: 77.62%\n","Time elapsed: 13.37 min\n","Epoch: 016/050 | Batch 000/266 | Loss: 0.4020\n","Epoch: 016/050 | Batch 050/266 | Loss: 0.2846\n","Epoch: 016/050 | Batch 100/266 | Loss: 0.3781\n","Epoch: 016/050 | Batch 150/266 | Loss: 0.3510\n","Epoch: 016/050 | Batch 200/266 | Loss: 0.4692\n","Epoch: 016/050 | Batch 250/266 | Loss: 0.4962\n","training accuracy: 82.42%\n","valid accuracy: 76.37%\n","Time elapsed: 14.26 min\n","Epoch: 017/050 | Batch 000/266 | Loss: 0.3440\n","Epoch: 017/050 | Batch 050/266 | Loss: 0.3849\n","Epoch: 017/050 | Batch 100/266 | Loss: 0.3189\n","Epoch: 017/050 | Batch 150/266 | Loss: 0.3611\n","Epoch: 017/050 | Batch 200/266 | Loss: 0.5052\n","Epoch: 017/050 | Batch 250/266 | Loss: 0.3443\n","training accuracy: 86.80%\n","valid accuracy: 78.98%\n","Time elapsed: 15.15 min\n","Epoch: 018/050 | Batch 000/266 | Loss: 0.3912\n","Epoch: 018/050 | Batch 050/266 | Loss: 0.3250\n","Epoch: 018/050 | Batch 100/266 | Loss: 0.2453\n","Epoch: 018/050 | Batch 150/266 | Loss: 0.3806\n","Epoch: 018/050 | Batch 200/266 | Loss: 0.3616\n","Epoch: 018/050 | Batch 250/266 | Loss: 0.3265\n","training accuracy: 87.61%\n","valid accuracy: 79.92%\n","Time elapsed: 16.04 min\n","Epoch: 019/050 | Batch 000/266 | Loss: 0.3043\n","Epoch: 019/050 | Batch 050/266 | Loss: 0.3221\n","Epoch: 019/050 | Batch 100/266 | Loss: 0.4061\n","Epoch: 019/050 | Batch 150/266 | Loss: 0.2301\n","Epoch: 019/050 | Batch 200/266 | Loss: 0.3515\n","Epoch: 019/050 | Batch 250/266 | Loss: 0.2703\n","training accuracy: 89.39%\n","valid accuracy: 80.37%\n","Time elapsed: 16.93 min\n","Epoch: 020/050 | Batch 000/266 | Loss: 0.2528\n","Epoch: 020/050 | Batch 050/266 | Loss: 0.2528\n","Epoch: 020/050 | Batch 100/266 | Loss: 0.2247\n","Epoch: 020/050 | Batch 150/266 | Loss: 0.3969\n","Epoch: 020/050 | Batch 200/266 | Loss: 0.2890\n","Epoch: 020/050 | Batch 250/266 | Loss: 0.3351\n","training accuracy: 90.59%\n","valid accuracy: 80.63%\n","Time elapsed: 17.81 min\n","Epoch: 021/050 | Batch 000/266 | Loss: 0.2280\n","Epoch: 021/050 | Batch 050/266 | Loss: 0.3016\n","Epoch: 021/050 | Batch 100/266 | Loss: 0.2382\n","Epoch: 021/050 | Batch 150/266 | Loss: 0.1862\n","Epoch: 021/050 | Batch 200/266 | Loss: 0.2989\n","Epoch: 021/050 | Batch 250/266 | Loss: 0.2516\n","training accuracy: 84.72%\n","valid accuracy: 76.12%\n","Time elapsed: 18.71 min\n","Epoch: 022/050 | Batch 000/266 | Loss: 0.3242\n","Epoch: 022/050 | Batch 050/266 | Loss: 0.3015\n","Epoch: 022/050 | Batch 100/266 | Loss: 0.2937\n","Epoch: 022/050 | Batch 150/266 | Loss: 0.3523\n","Epoch: 022/050 | Batch 200/266 | Loss: 0.3036\n","Epoch: 022/050 | Batch 250/266 | Loss: 0.3675\n","training accuracy: 90.17%\n","valid accuracy: 80.48%\n","Time elapsed: 19.59 min\n","Epoch: 023/050 | Batch 000/266 | Loss: 0.2873\n","Epoch: 023/050 | Batch 050/266 | Loss: 0.1397\n","Epoch: 023/050 | Batch 100/266 | Loss: 0.3403\n","Epoch: 023/050 | Batch 150/266 | Loss: 0.2765\n","Epoch: 023/050 | Batch 200/266 | Loss: 0.2996\n","Epoch: 023/050 | Batch 250/266 | Loss: 0.3217\n","training accuracy: 91.32%\n","valid accuracy: 81.17%\n","Time elapsed: 20.48 min\n","Epoch: 024/050 | Batch 000/266 | Loss: 0.2541\n","Epoch: 024/050 | Batch 050/266 | Loss: 0.2653\n","Epoch: 024/050 | Batch 100/266 | Loss: 0.3196\n","Epoch: 024/050 | Batch 150/266 | Loss: 0.2968\n","Epoch: 024/050 | Batch 200/266 | Loss: 0.2556\n","Epoch: 024/050 | Batch 250/266 | Loss: 0.2107\n","training accuracy: 91.43%\n","valid accuracy: 81.05%\n","Time elapsed: 21.37 min\n","Epoch: 025/050 | Batch 000/266 | Loss: 0.2195\n","Epoch: 025/050 | Batch 050/266 | Loss: 0.1656\n","Epoch: 025/050 | Batch 100/266 | Loss: 0.1731\n","Epoch: 025/050 | Batch 150/266 | Loss: 0.2153\n","Epoch: 025/050 | Batch 200/266 | Loss: 0.2055\n","Epoch: 025/050 | Batch 250/266 | Loss: 0.2600\n","training accuracy: 92.23%\n","valid accuracy: 81.10%\n","Time elapsed: 22.25 min\n","Epoch: 026/050 | Batch 000/266 | Loss: 0.1238\n","Epoch: 026/050 | Batch 050/266 | Loss: 0.1927\n","Epoch: 026/050 | Batch 100/266 | Loss: 0.2172\n","Epoch: 026/050 | Batch 150/266 | Loss: 0.2625\n","Epoch: 026/050 | Batch 200/266 | Loss: 0.2208\n","Epoch: 026/050 | Batch 250/266 | Loss: 0.1727\n","training accuracy: 92.68%\n","valid accuracy: 81.42%\n","Time elapsed: 23.14 min\n","Epoch: 027/050 | Batch 000/266 | Loss: 0.2543\n","Epoch: 027/050 | Batch 050/266 | Loss: 0.1353\n","Epoch: 027/050 | Batch 100/266 | Loss: 0.2206\n","Epoch: 027/050 | Batch 150/266 | Loss: 0.2279\n","Epoch: 027/050 | Batch 200/266 | Loss: 0.2454\n","Epoch: 027/050 | Batch 250/266 | Loss: 0.2585\n","training accuracy: 92.58%\n","valid accuracy: 81.02%\n","Time elapsed: 24.03 min\n","Epoch: 028/050 | Batch 000/266 | Loss: 0.3122\n","Epoch: 028/050 | Batch 050/266 | Loss: 0.1922\n","Epoch: 028/050 | Batch 100/266 | Loss: 0.1996\n","Epoch: 028/050 | Batch 150/266 | Loss: 0.2465\n","Epoch: 028/050 | Batch 200/266 | Loss: 0.2342\n","Epoch: 028/050 | Batch 250/266 | Loss: 0.3055\n","training accuracy: 93.01%\n","valid accuracy: 80.57%\n","Time elapsed: 24.92 min\n","Epoch: 029/050 | Batch 000/266 | Loss: 0.1589\n","Epoch: 029/050 | Batch 050/266 | Loss: 0.1290\n","Epoch: 029/050 | Batch 100/266 | Loss: 0.1324\n","Epoch: 029/050 | Batch 150/266 | Loss: 0.2556\n","Epoch: 029/050 | Batch 200/266 | Loss: 0.2054\n","Epoch: 029/050 | Batch 250/266 | Loss: 0.2755\n","training accuracy: 93.64%\n","valid accuracy: 81.25%\n","Time elapsed: 25.81 min\n","Epoch: 030/050 | Batch 000/266 | Loss: 0.1665\n","Epoch: 030/050 | Batch 050/266 | Loss: 0.2120\n","Epoch: 030/050 | Batch 100/266 | Loss: 0.2313\n","Epoch: 030/050 | Batch 150/266 | Loss: 0.2251\n","Epoch: 030/050 | Batch 200/266 | Loss: 0.2515\n","Epoch: 030/050 | Batch 250/266 | Loss: 0.1408\n","training accuracy: 93.95%\n","valid accuracy: 81.58%\n","Time elapsed: 26.70 min\n","Epoch: 031/050 | Batch 000/266 | Loss: 0.1582\n","Epoch: 031/050 | Batch 050/266 | Loss: 0.2112\n","Epoch: 031/050 | Batch 100/266 | Loss: 0.1110\n","Epoch: 031/050 | Batch 150/266 | Loss: 0.2154\n","Epoch: 031/050 | Batch 200/266 | Loss: 0.2021\n","Epoch: 031/050 | Batch 250/266 | Loss: 0.1668\n","training accuracy: 94.41%\n","valid accuracy: 81.48%\n","Time elapsed: 27.59 min\n","Epoch: 032/050 | Batch 000/266 | Loss: 0.1896\n","Epoch: 032/050 | Batch 050/266 | Loss: 0.1189\n","Epoch: 032/050 | Batch 100/266 | Loss: 0.2502\n","Epoch: 032/050 | Batch 150/266 | Loss: 0.1853\n","Epoch: 032/050 | Batch 200/266 | Loss: 0.2581\n","Epoch: 032/050 | Batch 250/266 | Loss: 0.2903\n","training accuracy: 93.95%\n","valid accuracy: 81.33%\n","Time elapsed: 28.49 min\n","Epoch: 033/050 | Batch 000/266 | Loss: 0.1868\n","Epoch: 033/050 | Batch 050/266 | Loss: 0.1272\n","Epoch: 033/050 | Batch 100/266 | Loss: 0.1343\n","Epoch: 033/050 | Batch 150/266 | Loss: 0.1545\n","Epoch: 033/050 | Batch 200/266 | Loss: 0.2179\n","Epoch: 033/050 | Batch 250/266 | Loss: 0.2966\n","training accuracy: 95.02%\n","valid accuracy: 81.93%\n","Time elapsed: 29.38 min\n","Epoch: 034/050 | Batch 000/266 | Loss: 0.0915\n","Epoch: 034/050 | Batch 050/266 | Loss: 0.1092\n","Epoch: 034/050 | Batch 100/266 | Loss: 0.1986\n","Epoch: 034/050 | Batch 150/266 | Loss: 0.2675\n","Epoch: 034/050 | Batch 200/266 | Loss: 0.1015\n","Epoch: 034/050 | Batch 250/266 | Loss: 0.1512\n","training accuracy: 94.23%\n","valid accuracy: 81.63%\n","Time elapsed: 30.27 min\n","Epoch: 035/050 | Batch 000/266 | Loss: 0.1395\n","Epoch: 035/050 | Batch 050/266 | Loss: 0.1876\n","Epoch: 035/050 | Batch 100/266 | Loss: 0.2126\n","Epoch: 035/050 | Batch 150/266 | Loss: 0.2668\n","Epoch: 035/050 | Batch 200/266 | Loss: 0.2182\n","Epoch: 035/050 | Batch 250/266 | Loss: 0.1173\n","training accuracy: 92.98%\n","valid accuracy: 81.50%\n","Time elapsed: 31.15 min\n","Epoch: 036/050 | Batch 000/266 | Loss: 0.1813\n","Epoch: 036/050 | Batch 050/266 | Loss: 0.2263\n","Epoch: 036/050 | Batch 100/266 | Loss: 0.1642\n","Epoch: 036/050 | Batch 150/266 | Loss: 0.1628\n","Epoch: 036/050 | Batch 200/266 | Loss: 0.2610\n","Epoch: 036/050 | Batch 250/266 | Loss: 0.2294\n","training accuracy: 92.47%\n","valid accuracy: 81.40%\n","Time elapsed: 32.04 min\n","Epoch: 037/050 | Batch 000/266 | Loss: 0.1984\n","Epoch: 037/050 | Batch 050/266 | Loss: 0.2219\n","Epoch: 037/050 | Batch 100/266 | Loss: 0.2397\n","Epoch: 037/050 | Batch 150/266 | Loss: 0.2183\n","Epoch: 037/050 | Batch 200/266 | Loss: 0.2278\n","Epoch: 037/050 | Batch 250/266 | Loss: 0.2238\n","training accuracy: 93.27%\n","valid accuracy: 82.13%\n","Time elapsed: 32.94 min\n","Epoch: 038/050 | Batch 000/266 | Loss: 0.3120\n","Epoch: 038/050 | Batch 050/266 | Loss: 0.1405\n","Epoch: 038/050 | Batch 100/266 | Loss: 0.1545\n","Epoch: 038/050 | Batch 150/266 | Loss: 0.2754\n","Epoch: 038/050 | Batch 200/266 | Loss: 0.2116\n","Epoch: 038/050 | Batch 250/266 | Loss: 0.1703\n","training accuracy: 92.09%\n","valid accuracy: 81.37%\n","Time elapsed: 33.82 min\n","Epoch: 039/050 | Batch 000/266 | Loss: 0.1569\n","Epoch: 039/050 | Batch 050/266 | Loss: 0.2228\n","Epoch: 039/050 | Batch 100/266 | Loss: 0.2185\n","Epoch: 039/050 | Batch 150/266 | Loss: 0.1499\n","Epoch: 039/050 | Batch 200/266 | Loss: 0.2019\n","Epoch: 039/050 | Batch 250/266 | Loss: 0.1447\n","training accuracy: 93.36%\n","valid accuracy: 82.37%\n","Time elapsed: 34.71 min\n","Epoch: 040/050 | Batch 000/266 | Loss: 0.1613\n","Epoch: 040/050 | Batch 050/266 | Loss: 0.1985\n","Epoch: 040/050 | Batch 100/266 | Loss: 0.1634\n","Epoch: 040/050 | Batch 150/266 | Loss: 0.2079\n","Epoch: 040/050 | Batch 200/266 | Loss: 0.1864\n","Epoch: 040/050 | Batch 250/266 | Loss: 0.1249\n","training accuracy: 93.76%\n","valid accuracy: 82.93%\n","Time elapsed: 35.60 min\n","Epoch: 041/050 | Batch 000/266 | Loss: 0.1897\n","Epoch: 041/050 | Batch 050/266 | Loss: 0.1500\n","Epoch: 041/050 | Batch 100/266 | Loss: 0.2308\n","Epoch: 041/050 | Batch 150/266 | Loss: 0.2038\n","Epoch: 041/050 | Batch 200/266 | Loss: 0.2426\n","Epoch: 041/050 | Batch 250/266 | Loss: 0.1828\n","training accuracy: 93.48%\n","valid accuracy: 83.05%\n","Time elapsed: 36.49 min\n","Epoch: 042/050 | Batch 000/266 | Loss: 0.2287\n","Epoch: 042/050 | Batch 050/266 | Loss: 0.2567\n","Epoch: 042/050 | Batch 100/266 | Loss: 0.2443\n","Epoch: 042/050 | Batch 150/266 | Loss: 0.2144\n","Epoch: 042/050 | Batch 200/266 | Loss: 0.3157\n","Epoch: 042/050 | Batch 250/266 | Loss: 0.1667\n","training accuracy: 90.11%\n","valid accuracy: 80.00%\n","Time elapsed: 37.38 min\n","Epoch: 043/050 | Batch 000/266 | Loss: 0.2841\n","Epoch: 043/050 | Batch 050/266 | Loss: 0.1480\n","Epoch: 043/050 | Batch 100/266 | Loss: 0.1887\n","Epoch: 043/050 | Batch 150/266 | Loss: 0.2729\n","Epoch: 043/050 | Batch 200/266 | Loss: 0.2207\n","Epoch: 043/050 | Batch 250/266 | Loss: 0.2333\n","training accuracy: 89.15%\n","valid accuracy: 78.70%\n","Time elapsed: 38.27 min\n","Epoch: 044/050 | Batch 000/266 | Loss: 0.2995\n","Epoch: 044/050 | Batch 050/266 | Loss: 0.1725\n","Epoch: 044/050 | Batch 100/266 | Loss: 0.2222\n","Epoch: 044/050 | Batch 150/266 | Loss: 0.2061\n","Epoch: 044/050 | Batch 200/266 | Loss: 0.1863\n","Epoch: 044/050 | Batch 250/266 | Loss: 0.1989\n","training accuracy: 92.44%\n","valid accuracy: 83.10%\n","Time elapsed: 39.16 min\n","Epoch: 045/050 | Batch 000/266 | Loss: 0.2186\n","Epoch: 045/050 | Batch 050/266 | Loss: 0.1884\n","Epoch: 045/050 | Batch 100/266 | Loss: 0.1523\n","Epoch: 045/050 | Batch 150/266 | Loss: 0.2148\n","Epoch: 045/050 | Batch 200/266 | Loss: 0.2272\n","Epoch: 045/050 | Batch 250/266 | Loss: 0.2513\n","training accuracy: 92.59%\n","valid accuracy: 83.20%\n","Time elapsed: 40.05 min\n","Epoch: 046/050 | Batch 000/266 | Loss: 0.1991\n","Epoch: 046/050 | Batch 050/266 | Loss: 0.3178\n","Epoch: 046/050 | Batch 100/266 | Loss: 0.2245\n","Epoch: 046/050 | Batch 150/266 | Loss: 0.2235\n","Epoch: 046/050 | Batch 200/266 | Loss: 0.2446\n","Epoch: 046/050 | Batch 250/266 | Loss: 0.2192\n","training accuracy: 92.64%\n","valid accuracy: 82.22%\n","Time elapsed: 40.94 min\n","Epoch: 047/050 | Batch 000/266 | Loss: 0.1798\n","Epoch: 047/050 | Batch 050/266 | Loss: 0.2303\n","Epoch: 047/050 | Batch 100/266 | Loss: 0.2892\n","Epoch: 047/050 | Batch 150/266 | Loss: 0.1327\n","Epoch: 047/050 | Batch 200/266 | Loss: 0.1648\n","Epoch: 047/050 | Batch 250/266 | Loss: 0.2482\n","training accuracy: 92.16%\n","valid accuracy: 82.62%\n","Time elapsed: 41.83 min\n","Epoch: 048/050 | Batch 000/266 | Loss: 0.1360\n","Epoch: 048/050 | Batch 050/266 | Loss: 0.1925\n","Epoch: 048/050 | Batch 100/266 | Loss: 0.2783\n","Epoch: 048/050 | Batch 150/266 | Loss: 0.2126\n","Epoch: 048/050 | Batch 200/266 | Loss: 0.1164\n","Epoch: 048/050 | Batch 250/266 | Loss: 0.2749\n","training accuracy: 92.70%\n","valid accuracy: 82.98%\n","Time elapsed: 42.72 min\n","Epoch: 049/050 | Batch 000/266 | Loss: 0.1270\n","Epoch: 049/050 | Batch 050/266 | Loss: 0.2993\n","Epoch: 049/050 | Batch 100/266 | Loss: 0.2531\n","Epoch: 049/050 | Batch 150/266 | Loss: 0.1558\n","Epoch: 049/050 | Batch 200/266 | Loss: 0.3661\n","Epoch: 049/050 | Batch 250/266 | Loss: 0.2605\n","training accuracy: 92.14%\n","valid accuracy: 82.50%\n","Time elapsed: 43.61 min\n","Epoch: 050/050 | Batch 000/266 | Loss: 0.2366\n","Epoch: 050/050 | Batch 050/266 | Loss: 0.3241\n","Epoch: 050/050 | Batch 100/266 | Loss: 0.2918\n","Epoch: 050/050 | Batch 150/266 | Loss: 0.3405\n","Epoch: 050/050 | Batch 200/266 | Loss: 0.2337\n","Epoch: 050/050 | Batch 250/266 | Loss: 0.2575\n","training accuracy: 89.26%\n","valid accuracy: 82.42%\n","Time elapsed: 44.50 min\n","Total Training Time: 44.50 min\n","Test accuracy: 82.03%\n"]}],"source":["start_time = time.time()\n","\n","for epoch in range(NUM_EPOCHS):\n","    model.train()\n","    for batch_idx, batch_data in enumerate(train_loader):\n","        \n","        text = batch_data.TEXT_COLUMN_NAME.to(DEVICE)\n","        labels = batch_data.LABEL_COLUMN_NAME.to(DEVICE)\n","\n","        ### FORWARD AND BACK PROP\n","        \n","        \n","        \n","        \n","        ### UPDATE MODEL PARAMETERS\n","        \n","        \n","        ### LOGGING\n","        if not batch_idx % 50:\n","            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n","                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n","                   f'Loss: {loss:.4f}')\n","\n","    with torch.set_grad_enabled(False):\n","        print(f'training accuracy: '\n","              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n","              f'\\nvalid accuracy: '\n","              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n","        \n","    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n","    \n","print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n","print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"]},{"cell_type":"markdown","metadata":{},"source":["# Model Testing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T16:41:22.981494Z","iopub.status.busy":"2022-01-22T16:41:22.981224Z","iopub.status.idle":"2022-01-22T16:41:23.185798Z","shell.execute_reply":"2022-01-22T16:41:23.185126Z","shell.execute_reply.started":"2022-01-22T16:41:22.981459Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Probability positive:\n"]},{"data":{"text/plain":["0.9985167384147644"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["import spacy\n","\n","\n","nlp = spacy.blank(\"en\")\n","\n","def predict_sentiment(model, sentence):\n","\n","    model.eval()\n","    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n","    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n","    length = [len(indexed)]\n","    tensor = torch.LongTensor(indexed).to(DEVICE)\n","    tensor = tensor.unsqueeze(1)\n","    length_tensor = torch.LongTensor(length)\n","    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n","    return prediction[0][1].item()\n","\n","print('Probability positive:')\n","predict_sentiment(model, \"This is such an awesome movie, I really love it!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-22T16:41:49.753493Z","iopub.status.busy":"2022-01-22T16:41:49.752937Z","iopub.status.idle":"2022-01-22T16:41:49.762087Z","shell.execute_reply":"2022-01-22T16:41:49.761053Z","shell.execute_reply.started":"2022-01-22T16:41:49.753453Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Probability positive:\n"]},{"data":{"text/plain":["0.0021373280324041843"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["print('Probability positive:')\n","predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":4}
